# Architecture Overview

## ğŸ—ï¸ System Architecture

The NIST Hardening Suite is a multiâ€‘layer security framework that transforms vanilla Linux servers into NIST 800â€‘53 compliant bastion hosts.

### Core Design Principles

1. **Idempotence** â€“ Safe to run repeatedly, produces identical results
2. **Providerâ€‘Agnostic** â€“ Works across cloud providers (Oracle Cloud, Hetzner, AWS, GCP, etc.)
3. **Defense in Depth** â€“ Multiple overlapping security controls
4. **Zero Trust Networking** â€“ Tailscale VPN replaces public SSH access
5. **Secretsâ€‘First** â€“ All credentials encrypted with Ansible Vault

## ğŸ“¦ Component Architecture

```mermaid
graph TB
    Ansible[Ansible Control Node] -->|SSH + Ansible Vault| OCI[OCI Production Node]
    Ansible -->|SSH + Ansible Vault| Hetzner[Hetzner Management Node]
    
    subgraph "Applied Security Layers"
        OCI --> L1["Layer 1: Base System<br/>Packages, timezone, locale, limits"]
        OCI --> L2["Layer 2: Account Security<br/>SSH hardening, fail2ban, root lockout"]
        OCI --> L3["Layer 3: Network Security<br/>UFW firewall, OCI killswitch"]
        OCI --> L4["Layer 4: Intrusion Prevention<br/>CrowdSec IPS, auditd monitoring"]
        OCI --> L5["Layer 5: VPN Mesh<br/>Tailscale zeroâ€‘trust network"]
        OCI --> L6["Layer 6: Container Runtime<br/>Docker Engine with pinned versions"]
    end
    
    subgraph "Monitoring & Management"
        CrowdSec[CrowdSec Console] -->|Hybrid signals| OCI
        CrowdSec -->|Hybrid signals| Hetzner
        Portainer[Portainer UI] -->|Docker API| OCI
        Portainer -->|Docker API| Hetzner
    end
```

## ğŸ” Security Architecture

### NIST 800â€‘53 Control Implementation

| Control | Layer | Implementation |
|---------|-------|----------------|
| **ACâ€‘2** Account Management | Layer 2 | SSH password auth disabled, root login prohibited, fail2ban bruteâ€‘force protection |
| **CMâ€‘7** Least Functionality | Layer 1 | Unused filesystems (cramfs, freevxfs, etc.) blacklisted, minimal packages |
| **SCâ€‘7** Boundary Protection | Layer 3 | UFW defaultâ€‘deny firewall, providerâ€‘specific iptables hardening, rateâ€‘limited SSH |
| **SIâ€‘4** System Monitoring | Layer 4 | CrowdSec collaborative IPS, realâ€‘time threat detection, log analysis |
| **AUâ€‘12** Audit Generation | Layer 4 | auditd systemâ€‘call monitoring, privileged command logging, tamperâ€‘resistant logs |
| **SCâ€‘28** Data at Rest | All Layers | Secrets via Ansible Vault; disk encryption handled at provisioning (audit only) |

### Network Architecture

```
Public Internet
    â”‚
    â”œâ”€â”€ Brain Node (Hetzner)
    â”‚   â”œâ”€â”€ SSH (rateâ€‘limited, public)
    â”‚   â”œâ”€â”€ HTTP/HTTPS (public)
    â”‚   â””â”€â”€ Tailscale VPN (100.64.0.0/10)
    â”‚
    â””â”€â”€ Muscle Nodes (Oracle Cloud)
        â”œâ”€â”€ SSH (Tailscale VPN only)
        â”œâ”€â”€ HTTP/HTTPS (public)
        â””â”€â”€ Tailscale VPN (100.64.0.0/10)
```

**Key Decisions:**
- **Public SSH only on Brain** â€“ Management node accessible for emergencies
- **Muscle nodes VPNâ€‘only** â€“ Compute workers isolated from public internet
- **Tailscale mesh** â€“ Zeroâ€‘trust networking with mutual TLS authentication
- **UFW over iptables** â€“ Simpler management, less errorâ€‘prone

## ğŸ”„ Execution Flow

### Bootstrap Phase (`site.yml`)
```
1. Preâ€‘flight validation (secrets, inventory)
2. Base system configuration (common role)
3. Security hardening (security role)
4. Intrusion prevention (crowdsec role)
5. VPN mesh establishment (tailscale_client role)
6. Docker engine installation (docker role)
7. Verification and status reporting
```

### Application Phase (`stacks.yml`)
```
1. Ingress layer deployment (Caddy reverse proxy)
2. Management layer deployment (Portainer UI + Edge Agents)
3. Observability configuration (VictoriaMetrics, Grafana, Loki)
```

## ğŸ—‚ï¸ Directory Structure

```
nist-hardening-suite/
â”œâ”€â”€ roles/                    # Ansible roles
â”‚   â”œâ”€â”€ common/              # Base system configuration
â”‚   â”œâ”€â”€ security/            # SSH, firewall, fail2ban hardening
â”‚   â”œâ”€â”€ crowdsec/            # Intrusion prevention system
â”‚   â”œâ”€â”€ tailscale_client/    # VPN mesh network
â”‚   â”œâ”€â”€ docker/              # Docker Engine installation
â”‚   â”œâ”€â”€ stack_ingress/       # Caddy reverse proxy
â”‚   â”œâ”€â”€ stack_portainer/     # Docker management UI
â”‚   â””â”€â”€ observability/       # Monitoring stack configs
â”œâ”€â”€ group_vars/              # Group variables
â”‚   â”œâ”€â”€ all/                 # Global variables & secrets
â”‚   â”œâ”€â”€ brain/               # Management node configs
â”‚   â””â”€â”€ muscle/              # Compute node configs
â”œâ”€â”€ inventory/               # Server inventory
â”œâ”€â”€ scripts/                 # Utility scripts
â”œâ”€â”€ site.yml                 # Main hardening playbook
â”œâ”€â”€ stacks.yml               # Application deployment playbook
â”œâ”€â”€ nuke.yml                 # Complete cleanup playbook
â””â”€â”€ ARCHITECTURE.md          # This document
```

## ğŸ”§ Technical Decisions

### Why Ansible?
- **Agentless** â€“ No software required on target servers
- **Idempotent** â€“ Safe for continuous compliance
- **Humanâ€‘readable** â€“ YAML syntax accessible to ops teams
- **Extensible** â€“ Large collection ecosystem

### Why Tailscale over WireGuard?
- **Zeroâ€‘config** â€“ No manual peer management
- **Centralized ACLs** â€“ Policyâ€‘based access control
- **NAT traversal** â€“ Works behind firewalls without port forwarding
- **Commercial support** â€“ Enterpriseâ€‘grade reliability

### Why CrowdSec over traditional IDS?
- **Collaborative** â€“ Learns from global threat intelligence
- **Low false positives** â€“ Behaviorâ€‘based detection
- **Containerâ€‘native** â€“ Lightweight, Dockerâ€‘friendly
- **Open core** â€“ Free local detection, paid console optional

### Why UFW over nftables/iptables?
- **Simpler syntax** â€“ Less errorâ€‘prone for basic rules
- **Ubuntu default** â€“ Wellâ€‘tested, widely supported
- **Docker integration** â€“ Automatic rule management for containers
- **Adequate for most use cases** â€“ Complex rules can use raw iptables

## ğŸ“ˆ Scaling Considerations

### Horizontal Scaling
- Add more `muscle` nodes to inventory
- Portainer Edge Agents automatically connect to management node (pullâ€‘based)
- CrowdSec signals shared across all nodes
- Tailscale mesh automatically includes new nodes

### Vertical Scaling
- Increase Docker resource limits in `daemon.json`
- Adjust UFW connection limits for highâ€‘traffic services
- Scale CrowdSec parser routines based on log volume
- Tune auditd rules for specific compliance requirements

### High Availability
- Brain node is single point of failure for management
- Muscle nodes are stateless, can be replaced automatically
- Consider deploying multiple brain nodes with load balancing
- Regular backups of Portainer configurations and Docker volumes

## ğŸš€ Deployment Considerations

### Cloud Provider Specifics
- **Oracle Cloud (OCI)** â€“ Requires iptables killswitch (providerâ€‘injected rules)
- **Hetzner** â€“ Clean slate, minimal provider interference
- **AWS/GCP/Azure** â€“ Tested but may need providerâ€‘specific firewall rules
- **Bare Metal** â€“ Works identically, no cloudâ€‘specific modifications

### Performance Impact
- **CPU**: <5% for security tools (CrowdSec, auditd)
- **Memory**: ~200MB for Docker, ~100MB for Tailscale, ~50MB for CrowdSec
- **Network**: Minimal overhead for Tailscale (WireGuardâ€‘based)
- **Disk**: ~2GB for Docker images, logs rotate automatically

## ğŸ” Monitoring & Observability

### Builtâ€‘In Monitoring
- **CrowdSec alerts** â€“ Realâ€‘time security incidents
- **auditd logs** â€“ Systemâ€‘call auditing (NIST AUâ€‘12)
- **Docker metrics** â€“ Container resource usage
- **Tailscale status** â€“ VPN connectivity and latency

### Optional Observability Stack
- **VictoriaMetrics** â€“ Timeâ€‘series database for metrics
- **Grafana** â€“ Dashboards and visualization
- **Loki** â€“ Log aggregation and querying
- **Uptime Kuma** â€“ Service availability monitoring

## ğŸ”’ Security Considerations & Known Risks

### Portainer Edge Agent Architecture
The suite deploys **Portainer Edge Agent** by default (`portainer-edge-agent.yml.j2`), which uses a **pullâ€‘based architecture** with **zero open ports** on managed nodes. This eliminates lateral movement risks identified in previous audits:

- **Zero open ports**: Edge Agents poll the Portainer server every 5 seconds via outbound connections
- **Reduced attack surface**: No API endpoints exposed on the Tailscale network
- **True Zero Trust**: Agents initiate connections; they don't listen for incoming requests
- **Docker socket**: Mounted readâ€‘only (`:ro`) to prevent container creation/removal

### Caddy Ingress & Zero Trust
The default `Caddyfile.j2` includes a `(vpn_only)` block that restricts access to Tailscale IPs (100.64.0.0/10). All example site definitions import this block, enforcing Zero Trust at the ingress layer. Remove `import vpn_only` from any site that requires public internet access.

### SCâ€‘28 Data at Rest Clarification
The NIST SCâ€‘28 control is partially implemented:
- **Secrets encryption**: Fully automated via Ansible Vault (secrets encrypted at rest)
- **Disk encryption**: **Not automated** â€“ the suite only audits for existing LUKS encryption (`lsblk -f | grep crypto_LUKS`). Full disk encryption must be configured manually at the provider or OS level.

### Tailscale Authentication Key Handling
Authentication keys are passed via `stdin` to `tailscale up --authkey=-` and never written to disk, eliminating the raceâ€‘condition risk of temporary file residue.

## ğŸ“š References

- [NIST 800â€‘53 Security Controls](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf)
- [CIS Benchmarks](https://www.cisecurity.org/cis-benchmarks)
- [Ansible Best Practices](https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html)
- [Tailscale Documentation](https://tailscale.com/kb/)
- [CrowdSec Documentation](https://docs.crowdsec.net/)